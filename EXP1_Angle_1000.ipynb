{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52023ae7-8fc7-4465-8152-a90ab9b60857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/huuthanhvy.nguyen001/.cache/huggingface/token\n",
      "Login successful\n",
      "Initializing llamaModel with model_name: raminguyen/llama-3.2-vision-instruct-1000-angle\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append('../')\n",
    "\n",
    "import LLMP as L\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "torch.cuda.empty_cache()\n",
    "sys.path.append('../')\n",
    "\n",
    "!rm -rf ~/.cache/huggingface\n",
    "\n",
    "from huggingface_hub import login\n",
    "login ('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')\n",
    "\n",
    "# Models\n",
    "model_instances = {\n",
    "    #\"gpt4o\": L.GPTModel(\"gpt-4o\"),\n",
    "    #\"LLaMA\": L.llamaModel(\"meta-llama/Llama-3.2-11B-Vision-Instruct\"), \n",
    "    \"CustomLLaMA\": L.llamaModel(\"raminguyen/llama-3.2-vision-instruct-1000-angle\"),\n",
    "    #\"GeminiProVision\": L.GeminiProVision(),  \n",
    "    #\"Gemini1_5Flash\": L.Gemini1_5Flash() \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6de2102-19f8-4f01-bfc5-52123fde0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: CustomLLaMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d234f671e0b94cf38d0817c0fdba797c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e050db2933c41ec9afecee10f8cc5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbe18608ac54c88aedab1bbcf8780b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ff15162d914255a127853995ce8cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475403eca298482fbe5bb13bde8c7d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e189ba870e43d190bfcc2d2f5cca31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d642f0ae08c744caa1d35f54c678986f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429500f2ac8e4f639f9d62c4e4f119b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3228e9d360d04ec2871033f6087c43dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/pytorch/lib/python3.11/site-packages/transformers/quantizers/auto.py:182: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78d727f7e6d4c16bbe406fa38849b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Run</th>\n",
       "      <th>Raw Answers</th>\n",
       "      <th>Parsed Answers</th>\n",
       "      <th>Mean</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MLAE</th>\n",
       "      <th>Times</th>\n",
       "      <th>Forced Repetitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[45.0]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>10.965874</td>\n",
       "      <td>6393.761873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[45.0]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.966145</td>\n",
       "      <td>6727.988958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[90.0]</td>\n",
       "      <td>90.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>10.550867</td>\n",
       "      <td>6375.811577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[70.0]</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.451469</td>\n",
       "      <td>6355.261803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[45.0]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.965965</td>\n",
       "      <td>5906.492949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[45.0]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>12.001452</td>\n",
       "      <td>6156.060934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[45.0]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>11.451276</td>\n",
       "      <td>6352.040768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[45.0]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>11.598111</td>\n",
       "      <td>6165.261507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[30.0]</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>6203.083277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CustomLLaMA</td>\n",
       "      <td>run_0</td>\n",
       "      <td>user\\n\\ngive me the exact angle degree in a nu...</td>\n",
       "      <td>[90.0]</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>6125.156403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model    Run                                        Raw Answers  \\\n",
       "0  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "1  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "2  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "3  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "4  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "5  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "6  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "7  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "8  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "9  CustomLLaMA  run_0  user\\n\\ngive me the exact angle degree in a nu...   \n",
       "\n",
       "  Parsed Answers  Mean     MSE       MLAE        Times  Forced Repetitions  \n",
       "0         [45.0]  45.0   400.0  10.965874  6393.761873                   0  \n",
       "1         [45.0]  45.0    25.0   8.966145  6727.988958                   0  \n",
       "2         [90.0]  90.0   225.0  10.550867  6375.811577                   0  \n",
       "3         [70.0]  70.0    49.0   9.451469  6355.261803                   0  \n",
       "4         [45.0]  45.0   100.0   9.965965  5906.492949                   0  \n",
       "5         [45.0]  45.0  1681.0  12.001452  6156.060934                   0  \n",
       "6         [45.0]  45.0   784.0  11.451276  6352.040768                   0  \n",
       "7         [45.0]  45.0   961.0  11.598111  6165.261507                   0  \n",
       "8         [30.0]  30.0     0.0  -3.000000  6203.083277                   0  \n",
       "9         [90.0]  90.0     0.0  -3.000000  6125.156403                   0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "bestquery = \"give me the exact angle degree in a number.\"\n",
    "\n",
    "# Run the evaluator\n",
    "e = L.Evaluator()\n",
    "\n",
    "# Run the query and collect results for each model individually, with delay for each image\n",
    "rows = []\n",
    "for model_name, model in model_instances.items():\n",
    "    print(f\"Running model: {model_name}\")\n",
    "    for idx, image in enumerate(images):\n",
    "        #time.sleep(2)  # Delay before processing each image\n",
    "        results = e.run([image], bestquery, {model_name: model})\n",
    "\n",
    "        # Collect the results in a structured manner\n",
    "        for model_data in results.values():\n",
    "            if isinstance(model_data, dict):\n",
    "                for run_name, run_data in model_data.items():\n",
    "                    time.sleep(5)  # Delay before processing each run\n",
    "                    if isinstance(run_data, dict):\n",
    "                        # Extracting raw answers and parsed answers\n",
    "                        raw_answers = run_data.get('raw_answers', [None])[0]\n",
    "                        parsed_answers = run_data.get('parsed_answers', [None])[0]\n",
    "\n",
    "                        # Extracting data from each run and storing in row\n",
    "                        row = {\n",
    "                            'Model': model_name,\n",
    "                            'Run': run_name,\n",
    "                            'Raw Answers': raw_answers,\n",
    "                            'Parsed Answers': parsed_answers,\n",
    "                            'Mean': run_data.get('mean'),\n",
    "                            'MSE': run_data.get('mse'),\n",
    "                            'MLAE': run_data.get('mlae'),\n",
    "                            'Times': run_data.get('times', [None])[0],\n",
    "                            'Forced Repetitions': run_data.get('forced_repetitions')\n",
    "                        }\n",
    "                        rows.append(row)\n",
    "\n",
    "# Convert the rows into a DataFrame\n",
    "result_df = pd.DataFrame(rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
